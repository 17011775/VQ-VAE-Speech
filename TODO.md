* log MSE instead of MSE for vq_vae_features ?
* language entropy using a character LM like DeepSpeech
* plot spectrogram of input/output features
* plot/compare vq output with/wo jitter
* Update README
* Compute all MFCC of datasets before the training
* LibriSpeech dataloader with the right dataset
* Handle the flow_wavenet and clarinet as possible decoders in vq_vae_wavenet decoder